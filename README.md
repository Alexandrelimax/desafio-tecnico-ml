# ðŸŽ“ Student Performance â€” Desafio TÃ©cnico de Machine Learning

Este repositÃ³rio contÃ©m a soluÃ§Ã£o para um **desafio tÃ©cnico de Machine Learning**, cujo objetivo Ã©
**analisar fatores associados ao desempenho escolar** e construir um **modelo baseline de classificaÃ§Ã£o**
para prever a **aprovaÃ§Ã£o de estudantes**, utilizando dados pÃºblicos.

O projeto foi desenvolvido com foco em:
- Clareza analÃ­tica
- Storytelling orientado por dados
- Pipeline de ML reprodutÃ­vel
- Simplicidade e boas prÃ¡ticas

---

## ðŸ“Š Dataset

- Fonte: **Kaggle**
- Dataset: *Student Performance Dataset*
- Link:  
  https://www.kaggle.com/datasets/dskagglemt/student-performance-data-set?select=student-mat.csv

O dataset original Ã© proveniente do **UCI Machine Learning Repository** e contÃ©m informaÃ§Ãµes
demogrÃ¡ficas, socioeconÃ´micas e educacionais de estudantes do ensino mÃ©dio em Portugal.

### Principais grupos de variÃ¡veis
- EducaÃ§Ã£o: tempo de estudo, reprovaÃ§Ãµes, notas
- FamÃ­lia: escolaridade dos pais, suporte familiar
- Infraestrutura/contexto: acesso Ã  internet, tempo de deslocamento
- Comportamento: faltas, atividades extracurriculares

---

## ðŸŽ¯ Objetivo do projeto

1. **Explorar e entender os dados** por meio de anÃ¡lise exploratÃ³ria e visualizaÃ§Ãµes (storytelling).
2. **Definir um problema de Machine Learning claro e interpretÃ¡vel**.
3. **Construir um modelo baseline de classificaÃ§Ã£o** para prever aprovaÃ§Ã£o/reprovaÃ§Ã£o.
4. **Salvar o modelo treinado** em formato reutilizÃ¡vel (`joblib`).

---

## ðŸ§  DefiniÃ§Ã£o do problema de Machine Learning

- Tipo: **ClassificaÃ§Ã£o binÃ¡ria**
- Target criado:
  - `target_pass = 1` â†’ aluno aprovado (`G3 >= 10`)
  - `target_pass = 0` â†’ aluno reprovado (`G3 < 10`)

As notas intermediÃ¡rias (`G1`, `G2`) **nÃ£o sÃ£o utilizadas como features** no modelo baseline
para evitar **Data Leakage** (vazamento de informaÃ§Ã£o).

---

## ðŸ“ Estrutura do repositÃ³rio

```text
DESAFIO_TECNICO_ML/
â”‚
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ model_baseline_rf.joblib
â”œâ”€â”€ data/
â”‚   â””â”€â”€ student-mat.csv 
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_storytelling_student_performance.ipynb
â”‚   â””â”€â”€ 02_model_baseline.ipynb
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .venv/ 
```
---

## 8. PrÃ³ximos passos - Melhorias do modelo

PossÃ­veis extensÃµes naturais deste trabalho incluem:
- engenharia de features avanÃ§ada
- validaÃ§Ã£o cruzada
- tuning de hiperparÃ¢metros
- modelos mais complexos
- deploy e monitoramento

---

## 9. PrÃ³ximos passos â€” Ciclo de Vida do Modelo e MLOps (VisÃ£o GCP)

AlÃ©m das evoluÃ§Ãµes analÃ­ticas e de modelagem, um prÃ³ximo passo natural
para este projeto Ã© a estruturaÃ§Ã£o do **ciclo de vida completo do modelo**
sob uma perspectiva de **MLOps**, considerando escalabilidade, custo
e governanÃ§a.

Abaixo descrevemos possÃ­veis extensÃµes arquiteturais no contexto do
Google Cloud Platform (GCP).

---

### 9.1 OrquestraÃ§Ã£o e pipelines de treinamento

A etapa de treinamento e re-treinamento do modelo pode ser orquestrada
por pipelines automatizados, de acordo com a complexidade do cenÃ¡rio.

PossÃ­veis abordagens:

- **Vertex AI Pipelines**  
  - Adequado para pipelines de ML gerenciados
  - IntegraÃ§Ã£o nativa com experiments, artefatos e model registry
  - Indicado para cenÃ¡rios com maior maturidade de ML

- **Apache Airflow**  
  - Para maior controle e flexibilidade da DAG
  - Pode ser executado via:
    - **Cloud Composer** (serviÃ§o gerenciado)
    - **Airflow em Compute Engine**, quando o custo for fator decisivo
  - Permite integrar facilmente etapas como:
    - ingestÃ£o de dados
    - feature engineering
    - treinamento
    - avaliaÃ§Ã£o
    - persistÃªncia de artefatos

A escolha entre essas abordagens depende do equilÃ­brio entre
**custo operacional, complexidade e necessidade de governanÃ§a**.

---

### 9.2 Armazenamento e processamento de dados

Considerando o volume e a natureza dos dados, o
**BigQuery** se apresenta como um candidato natural para:

- armazenamento analÃ­tico dos dados brutos e tratados
- execuÃ§Ã£o de transformaÃ§Ãµes em larga escala
- criaÃ§Ã£o de camadas (raw, refined, curated)

Nesse contexto:

- Os dados poderiam ser ingeridos como tabelas externas ou nativas
- O dataset consolidado para modelagem poderia ser versionado no BigQuery
- O BigQuery serviria como fonte Ãºnica de verdade para mÃºltiplos modelos

---

### 9.3 Feature engineering e governanÃ§a de transformaÃ§Ãµes

Para cenÃ¡rios em que o **BigQuery** seja o principal motor analÃ­tico,
o **Dataform** surge como ferramenta adequada para:

- versionamento de transformaÃ§Ãµes SQL
- definiÃ§Ã£o de dependÃªncias entre tabelas
- execuÃ§Ã£o incremental
- integraÃ§Ã£o com CI/CD

Nesse modelo:
- o ciclo de vida dos dados Ã© tratado no Dataform
- a governanÃ§a das features ocorre antes da modelagem
- mudanÃ§as estruturais passam por versionamento e revisÃ£o

---

### 9.4 EstratÃ©gias de modelagem: BigQuery ML vs modelos customizados

Duas estratÃ©gias distintas podem ser consideradas:

#### Modelos com BigQuery ML
- Treinamento e inferÃªncia executados diretamente no BigQuery
- Ciclo de vida do modelo gerenciado pela prÃ³pria plataforma
- IntegraÃ§Ã£o natural com Dataform e pipelines SQL
- Menor esforÃ§o operacional

#### Modelos customizados (scikit-learn, etc.)
- Maior flexibilidade algorÃ­tmica
- Treinamento orquestrado via Airflow ou Vertex Pipelines
- PersistÃªncia de artefatos (ex: `joblib`) em:
  - Artifact Registry
  - Cloud Storage
- Deploy via:
  - Vertex AI
  - Cloud Run
  - serviÃ§os customizados

A escolha depende do grau de customizaÃ§Ã£o e controle desejado.

---

### 9.5 CI/CD e versionamento de artefatos

Para modelos customizados, o ciclo de CI/CD pode ser estruturado com:

- **GitHub** como repositÃ³rio de cÃ³digo
- **Cloud Build** para:
  - execuÃ§Ã£o de testes
  - treinamento automatizado
  - validaÃ§Ã£o de mÃ©tricas
  - geraÃ§Ã£o de artefatos
- **Artifact Registry** para versionamento de:
  - imagens Docker
  - modelos treinados
  - dependÃªncias

Essa abordagem permite:
- reprodutibilidade
- rastreabilidade
- rollback controlado de modelos

---

### 9.6 Monitoramento do modelo em produÃ§Ã£o

ApÃ³s o deploy, o modelo deve ser monitorado continuamente para garantir
qualidade e confiabilidade.

Aspectos importantes incluem:

- **Model Monitoring**
  - detecÃ§Ã£o de data drift
  - detecÃ§Ã£o de prediction drift
  - acompanhamento de mÃ©tricas ao longo do tempo
  - disparo de e-mails

- **Monitoramento operacional**
  - latÃªncia
  - taxa de erro
  - custo de inferÃªncia

No GCP, essas capacidades podem ser implementadas via:
- Vertex AI Model Monitoring
- Cloud Monitoring e Logging
- mÃ©tricas customizadas

---

### 9.7 ConsideraÃ§Ãµes finais sobre MLOps

A incorporaÃ§Ã£o de prÃ¡ticas de MLOps transforma este projeto de um
exercÃ­cio analÃ­tico em um **sistema de ML sustentÃ¡vel**, capaz de:

- evoluir com novos dados
- manter governanÃ§a e controle
- equilibrar custo e complexidade
- operar de forma confiÃ¡vel em produÃ§Ã£o

Essa etapa nÃ£o faz parte do escopo do desafio tÃ©cnico,
mas representa uma **evoluÃ§Ã£o natural** do trabalho desenvolvido.


**Projeto desenvolvido por Alexandre de Almeida Lima para desafio tÃ©cnico.**
